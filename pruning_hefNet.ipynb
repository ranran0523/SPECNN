{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "\n",
    "from pruning.layers import MaskedLinear, MaskedConv2d \n",
    "from pruning.methods import filter_prune\n",
    "from pruning.utils import to_var, prune_rate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class polynom_act(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=None, beta=None, c=None):\n",
    "        super(polynom_act, self).__init__()\n",
    "#         self.alpha = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "#         self.beta = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "#         self.c = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.FloatTensor([0.1]), requires_grad=True)\n",
    "        self.beta = nn.Parameter(torch.FloatTensor([1]), requires_grad=True)\n",
    "        self.c = nn.Parameter(torch.FloatTensor([0.1]), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        return (self.alpha * (x ** 2) + self.beta * x + self.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list=[256,128,64]\n",
    "#channel_list=[64,128,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hefNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(hefNet, self).__init__()\n",
    "        \n",
    "        activation=nn.ReLU(inplace=True)\n",
    "        #activation=polynom_act()\n",
    "        \n",
    "        self.conv1 = MaskedConv2d(3, channel_list[0], kernel_size=3, padding=0, stride=1)\n",
    "        nn.init.xavier_uniform(self.conv1.weight)\n",
    "        \n",
    "        self.bn1=nn.BatchNorm2d(channel_list[0])\n",
    "        self.relu1 = activation\n",
    "\n",
    "        self.conv2 = MaskedConv2d(channel_list[0], channel_list[1], kernel_size=3, stride=1,groups=8)\n",
    "        nn.init.xavier_uniform(self.conv2.weight)\n",
    "        \n",
    "        self.bn2=nn.BatchNorm2d(channel_list[1])\n",
    "        self.relu2= activation\n",
    "        self.avgpool1=nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv3 = MaskedConv2d(channel_list[1], channel_list[2], kernel_size=3, stride=1,groups=8)\n",
    "        nn.init.xavier_uniform(self.conv3.weight)\n",
    "        \n",
    "        self.bn3=nn.BatchNorm2d(channel_list[2])\n",
    "        self.relu3= activation\n",
    "        self.avgpool2=nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4 = MaskedConv2d(channel_list[2], channel_list[2], kernel_size=3, stride=1,groups=8)\n",
    "        nn.init.xavier_uniform(self.conv4.weight)\n",
    "        \n",
    "        self.bn4=nn.BatchNorm2d(channel_list[2])\n",
    "        self.relu4= activation\n",
    "        self.avgpool3=nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.dropout=nn.Dropout2d(0.5)\n",
    "        self.linear1 = nn.Linear(channel_list[2]*2*2,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.avgpool1(self.relu1(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        x = self.avgpool2(self.relu2(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = self.avgpool3(self.relu3(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        #print(out.shape)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear1(x)\n",
    "   \n",
    "        return x\n",
    "\n",
    "    def set_masks(self, masks):\n",
    "        \n",
    "        self.conv1.set_mask(torch.from_numpy(masks[0]))\n",
    "        self.conv2.set_mask(torch.from_numpy(masks[1]))\n",
    "        self.conv3.set_mask(torch.from_numpy(masks[2]))\n",
    "        self.conv4.set_mask(torch.from_numpy(masks[3]))\n",
    "        self.linear1.set_mask(torch.from_numpy(masks[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'pruning_perc': 50.,\n",
    "    'batch_size': 128, \n",
    "    'test_batch_size': 100,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum':0.9,\n",
    "    'amsgrad':True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data loaders\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='../data/', train=True, download=True,transform=transform_train)\n",
    "loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=param['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='../data/', train=False, transform=transform_test)\n",
    "loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=param['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, param, loader_train, loader_val=None):\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(param['num_epochs']):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, param['num_epochs']))\n",
    "\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            \n",
    "            x_var, y_var = to_var(x), to_var(y.long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            loss = loss_fn(scores, y_var)\n",
    "\n",
    "            if (t + 1) % 100 == 0:\n",
    "\n",
    "                print('t = %d, loss = %.8f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 ==0:\n",
    "            \n",
    "            torch.save(model.state_dict(), 'models/hefNet_pretrained'+str(epoch+1)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "    num_correct, num_samples = 0, len(loader.dataset)\n",
    "    for x, y in loader:\n",
    "        x_var = to_var(x, volatile=True)\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "\n",
    "    acc = float(num_correct) / num_samples\n",
    "\n",
    "    print('Test accuracy: {:.2f}% ({}/{})'.format(\n",
    "        100.*acc,\n",
    "        num_correct,\n",
    "        num_samples,\n",
    "        ))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rar418/.conda/envs/st-gcn/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  if __name__ == '__main__':\n",
      "/home/rar418/.conda/envs/st-gcn/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/rar418/.conda/envs/st-gcn/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/rar418/.conda/envs/st-gcn/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "net=hefNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hefNet(\n",
       "  (conv1): MaskedConv2d(3, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (conv2): MaskedConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), groups=8)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv3): MaskedConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), groups=8)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv4): MaskedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=8)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu4): ReLU(inplace=True)\n",
       "  (avgpool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
       "  (linear1): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)  #level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict=torch.load('./models/hefNet_pretrained30.pkl')\n",
    "model_dict=net.state_dict()\n",
    "pretrained_dict={k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "model_dict.update(pretrained_dict)\n",
    "net.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 100\n",
      "t = 100, loss = 2.21485257\n",
      "t = 200, loss = 2.14664006\n",
      "t = 300, loss = 2.13221741\n",
      "Starting epoch 2 / 100\n",
      "t = 100, loss = 2.04743052\n",
      "t = 200, loss = 1.98518133\n",
      "t = 300, loss = 1.97212470\n",
      "Starting epoch 3 / 100\n",
      "t = 100, loss = 1.93884635\n",
      "t = 200, loss = 1.96644759\n",
      "t = 300, loss = 1.87321281\n",
      "Starting epoch 4 / 100\n",
      "t = 100, loss = 1.88484323\n",
      "t = 200, loss = 1.92369521\n",
      "t = 300, loss = 1.80840874\n",
      "Starting epoch 5 / 100\n",
      "t = 100, loss = 1.85863173\n",
      "t = 200, loss = 1.75637519\n",
      "t = 300, loss = 1.71697497\n",
      "Starting epoch 6 / 100\n",
      "t = 100, loss = 1.77851784\n",
      "t = 200, loss = 1.72398472\n",
      "t = 300, loss = 1.71608949\n",
      "Starting epoch 7 / 100\n",
      "t = 100, loss = 1.63726187\n",
      "t = 200, loss = 1.72326267\n",
      "t = 300, loss = 1.70693493\n",
      "Starting epoch 8 / 100\n",
      "t = 100, loss = 1.58367813\n",
      "t = 200, loss = 1.61768746\n",
      "t = 300, loss = 1.58114171\n",
      "Starting epoch 9 / 100\n",
      "t = 100, loss = 1.53206801\n",
      "t = 200, loss = 1.53416073\n",
      "t = 300, loss = 1.67399013\n",
      "Starting epoch 10 / 100\n",
      "t = 100, loss = 1.63632953\n",
      "t = 200, loss = 1.67977202\n",
      "t = 300, loss = 1.60298550\n",
      "Starting epoch 11 / 100\n",
      "t = 100, loss = 1.61543238\n",
      "t = 200, loss = 1.62399900\n",
      "t = 300, loss = 1.53189886\n",
      "Starting epoch 12 / 100\n",
      "t = 100, loss = 1.51031220\n",
      "t = 200, loss = 1.46524572\n",
      "t = 300, loss = 1.47299469\n",
      "Starting epoch 13 / 100\n",
      "t = 100, loss = 1.38649321\n",
      "t = 200, loss = 1.68131125\n",
      "t = 300, loss = 1.38537514\n",
      "Starting epoch 14 / 100\n",
      "t = 100, loss = 1.55696499\n",
      "t = 200, loss = 1.47702241\n",
      "t = 300, loss = 1.51155329\n",
      "Starting epoch 15 / 100\n",
      "t = 100, loss = 1.41442978\n",
      "t = 200, loss = 1.48338640\n",
      "t = 300, loss = 1.48756742\n",
      "Starting epoch 16 / 100\n",
      "t = 100, loss = 1.51103532\n",
      "t = 200, loss = 1.38084567\n",
      "t = 300, loss = 1.39600968\n",
      "Starting epoch 17 / 100\n",
      "t = 100, loss = 1.34063077\n",
      "t = 200, loss = 1.34065402\n",
      "t = 300, loss = 1.47341359\n",
      "Starting epoch 18 / 100\n",
      "t = 100, loss = 1.40871644\n",
      "t = 200, loss = 1.39617360\n",
      "t = 300, loss = 1.41390562\n",
      "Starting epoch 19 / 100\n",
      "t = 100, loss = 1.39470971\n",
      "t = 200, loss = 1.26688683\n",
      "t = 300, loss = 1.31149888\n",
      "Starting epoch 20 / 100\n",
      "t = 100, loss = 1.37923980\n",
      "t = 200, loss = 1.27812469\n",
      "t = 300, loss = 1.36604965\n",
      "Starting epoch 21 / 100\n",
      "t = 100, loss = 1.39103043\n",
      "t = 200, loss = 1.28839219\n",
      "t = 300, loss = 1.31169581\n",
      "Starting epoch 22 / 100\n",
      "t = 100, loss = 1.24794245\n",
      "t = 200, loss = 1.27366138\n",
      "t = 300, loss = 1.23617840\n",
      "Starting epoch 23 / 100\n",
      "t = 100, loss = 1.22945249\n",
      "t = 200, loss = 1.17113757\n",
      "t = 300, loss = 1.19749260\n",
      "Starting epoch 24 / 100\n",
      "t = 100, loss = 1.25685322\n",
      "t = 200, loss = 1.33351588\n",
      "t = 300, loss = 1.45481861\n",
      "Starting epoch 25 / 100\n",
      "t = 100, loss = 1.26996553\n",
      "t = 200, loss = 1.23798668\n",
      "t = 300, loss = 1.33344483\n",
      "Starting epoch 26 / 100\n",
      "t = 100, loss = 1.24462795\n",
      "t = 200, loss = 1.31335771\n",
      "t = 300, loss = 1.43750596\n",
      "Starting epoch 27 / 100\n",
      "t = 100, loss = 1.16963232\n",
      "t = 200, loss = 1.41078544\n",
      "t = 300, loss = 1.31206286\n",
      "Starting epoch 28 / 100\n",
      "t = 100, loss = 1.20594060\n",
      "t = 200, loss = 1.02266788\n",
      "t = 300, loss = 1.37127221\n",
      "Starting epoch 29 / 100\n",
      "t = 100, loss = 1.21124387\n",
      "t = 200, loss = 1.24370348\n",
      "t = 300, loss = 1.15491152\n",
      "Starting epoch 30 / 100\n",
      "t = 100, loss = 1.23709047\n",
      "t = 200, loss = 1.12248421\n",
      "t = 300, loss = 1.14036334\n",
      "Starting epoch 31 / 100\n",
      "t = 100, loss = 1.13994956\n",
      "t = 200, loss = 1.13108993\n",
      "t = 300, loss = 1.29539299\n",
      "Starting epoch 32 / 100\n",
      "t = 100, loss = 1.11058140\n",
      "t = 200, loss = 1.30120337\n",
      "t = 300, loss = 1.31186783\n",
      "Starting epoch 33 / 100\n",
      "t = 100, loss = 1.14754081\n",
      "t = 200, loss = 1.18374479\n",
      "t = 300, loss = 1.16625571\n",
      "Starting epoch 34 / 100\n",
      "t = 100, loss = 1.02789831\n",
      "t = 200, loss = 1.17055786\n",
      "t = 300, loss = 1.26676548\n",
      "Starting epoch 35 / 100\n",
      "t = 100, loss = 1.17167222\n",
      "t = 200, loss = 1.14241326\n",
      "t = 300, loss = 1.18483436\n",
      "Starting epoch 36 / 100\n",
      "t = 100, loss = 1.20664895\n",
      "t = 200, loss = 1.19634271\n",
      "t = 300, loss = 1.23397338\n",
      "Starting epoch 37 / 100\n",
      "t = 100, loss = 0.99851871\n",
      "t = 200, loss = 1.08970630\n",
      "t = 300, loss = 1.21210575\n",
      "Starting epoch 38 / 100\n",
      "t = 100, loss = 1.39696109\n",
      "t = 200, loss = 1.26182961\n",
      "t = 300, loss = 1.47137022\n",
      "Starting epoch 39 / 100\n",
      "t = 100, loss = 1.10656202\n",
      "t = 200, loss = 1.33175218\n",
      "t = 300, loss = 1.14367855\n",
      "Starting epoch 40 / 100\n",
      "t = 100, loss = 1.20185935\n",
      "t = 200, loss = 1.22583282\n",
      "t = 300, loss = 1.17110515\n",
      "Starting epoch 41 / 100\n",
      "t = 100, loss = 1.01579380\n",
      "t = 200, loss = 1.13910294\n",
      "t = 300, loss = 1.13692939\n",
      "Starting epoch 42 / 100\n",
      "t = 100, loss = 1.22696304\n",
      "t = 200, loss = 1.05541503\n",
      "t = 300, loss = 0.93633640\n",
      "Starting epoch 43 / 100\n",
      "t = 100, loss = 1.05758107\n",
      "t = 200, loss = 1.17743027\n",
      "t = 300, loss = 1.05175924\n",
      "Starting epoch 44 / 100\n",
      "t = 100, loss = 1.21033168\n",
      "t = 200, loss = 1.02799952\n",
      "t = 300, loss = 0.95592278\n",
      "Starting epoch 45 / 100\n",
      "t = 100, loss = 1.24634457\n",
      "t = 200, loss = 1.06981766\n",
      "t = 300, loss = 1.05210769\n",
      "Starting epoch 46 / 100\n",
      "t = 100, loss = 1.14326680\n",
      "t = 200, loss = 1.11389887\n",
      "t = 300, loss = 1.16098464\n",
      "Starting epoch 47 / 100\n",
      "t = 100, loss = 1.14095879\n",
      "t = 200, loss = 1.00881553\n",
      "t = 300, loss = 1.19331861\n",
      "Starting epoch 48 / 100\n",
      "t = 100, loss = 1.12860596\n",
      "t = 200, loss = 1.07660294\n",
      "t = 300, loss = 1.03962493\n",
      "Starting epoch 49 / 100\n",
      "t = 100, loss = 0.99903184\n",
      "t = 200, loss = 1.07396758\n",
      "t = 300, loss = 1.20596457\n",
      "Starting epoch 50 / 100\n",
      "t = 100, loss = 1.22110677\n",
      "t = 200, loss = 1.08765185\n",
      "t = 300, loss = 1.11661983\n",
      "Starting epoch 51 / 100\n",
      "t = 100, loss = 0.94702852\n",
      "t = 200, loss = 1.11972773\n",
      "t = 300, loss = 1.09138703\n",
      "Starting epoch 52 / 100\n",
      "t = 100, loss = 1.05188513\n",
      "t = 200, loss = 1.02454829\n",
      "t = 300, loss = 1.09953773\n",
      "Starting epoch 53 / 100\n",
      "t = 100, loss = 0.94568640\n",
      "t = 200, loss = 0.95136553\n",
      "t = 300, loss = 0.99789500\n",
      "Starting epoch 54 / 100\n",
      "t = 100, loss = 1.07014620\n",
      "t = 200, loss = 1.04378378\n",
      "t = 300, loss = 0.93302333\n",
      "Starting epoch 55 / 100\n",
      "t = 100, loss = 0.90801984\n",
      "t = 200, loss = 1.06644428\n",
      "t = 300, loss = 1.01712799\n",
      "Starting epoch 56 / 100\n",
      "t = 100, loss = 0.92678082\n",
      "t = 200, loss = 0.96944767\n",
      "t = 300, loss = 1.01336706\n",
      "Starting epoch 57 / 100\n",
      "t = 100, loss = 1.08430481\n",
      "t = 200, loss = 1.32041132\n",
      "t = 300, loss = 1.04553032\n",
      "Starting epoch 58 / 100\n",
      "t = 100, loss = 0.96173912\n",
      "t = 200, loss = 1.10817266\n",
      "t = 300, loss = 1.19273937\n",
      "Starting epoch 59 / 100\n",
      "t = 100, loss = 1.10171568\n",
      "t = 200, loss = 1.02950370\n",
      "t = 300, loss = 1.19724596\n",
      "Starting epoch 60 / 100\n",
      "t = 100, loss = 0.89090943\n",
      "t = 200, loss = 1.00906754\n",
      "t = 300, loss = 0.98432082\n",
      "Starting epoch 61 / 100\n",
      "t = 100, loss = 1.01367939\n",
      "t = 200, loss = 1.06147552\n",
      "t = 300, loss = 1.00783730\n",
      "Starting epoch 62 / 100\n",
      "t = 100, loss = 0.87765896\n",
      "t = 200, loss = 0.90536159\n",
      "t = 300, loss = 0.98237550\n",
      "Starting epoch 63 / 100\n",
      "t = 100, loss = 0.97903711\n",
      "t = 200, loss = 0.88560498\n",
      "t = 300, loss = 1.05164301\n",
      "Starting epoch 64 / 100\n",
      "t = 100, loss = 0.99532855\n",
      "t = 200, loss = 1.00161040\n",
      "t = 300, loss = 0.90824276\n",
      "Starting epoch 65 / 100\n",
      "t = 100, loss = 1.01600111\n",
      "t = 200, loss = 1.04162419\n",
      "t = 300, loss = 0.90762156\n",
      "Starting epoch 66 / 100\n",
      "t = 100, loss = 0.93342710\n",
      "t = 200, loss = 1.19353735\n",
      "t = 300, loss = 1.05775046\n",
      "Starting epoch 67 / 100\n",
      "t = 100, loss = 1.02145696\n",
      "t = 200, loss = 1.01457238\n",
      "t = 300, loss = 0.98176485\n",
      "Starting epoch 68 / 100\n",
      "t = 100, loss = 0.86528826\n",
      "t = 200, loss = 1.06965470\n",
      "t = 300, loss = 1.01725173\n",
      "Starting epoch 69 / 100\n",
      "t = 100, loss = 0.98503083\n",
      "t = 200, loss = 0.92777312\n",
      "t = 300, loss = 0.91189957\n",
      "Starting epoch 70 / 100\n",
      "t = 100, loss = 0.87972289\n",
      "t = 200, loss = 0.98701489\n",
      "t = 300, loss = 0.89284831\n",
      "Starting epoch 71 / 100\n",
      "t = 100, loss = 0.89611316\n",
      "t = 200, loss = 0.89076257\n",
      "t = 300, loss = 0.90117568\n",
      "Starting epoch 72 / 100\n",
      "t = 100, loss = 1.10625303\n",
      "t = 200, loss = 1.01268578\n",
      "t = 300, loss = 0.90710098\n",
      "Starting epoch 73 / 100\n",
      "t = 100, loss = 0.91779584\n",
      "t = 200, loss = 0.96454251\n",
      "t = 300, loss = 0.82443160\n",
      "Starting epoch 74 / 100\n",
      "t = 100, loss = 0.85846835\n",
      "t = 200, loss = 0.95651078\n",
      "t = 300, loss = 0.87633455\n",
      "Starting epoch 75 / 100\n",
      "t = 100, loss = 0.96859378\n",
      "t = 200, loss = 0.98276877\n",
      "t = 300, loss = 0.96759242\n",
      "Starting epoch 76 / 100\n",
      "t = 100, loss = 1.04132938\n",
      "t = 200, loss = 0.94643509\n",
      "t = 300, loss = 0.93425411\n",
      "Starting epoch 77 / 100\n",
      "t = 100, loss = 0.93909669\n",
      "t = 200, loss = 0.96628511\n",
      "t = 300, loss = 0.91872942\n",
      "Starting epoch 78 / 100\n",
      "t = 100, loss = 0.98427087\n",
      "t = 200, loss = 1.11911082\n",
      "t = 300, loss = 0.87708282\n",
      "Starting epoch 79 / 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 100, loss = 0.93224657\n",
      "t = 200, loss = 0.85200053\n",
      "t = 300, loss = 0.95617455\n",
      "Starting epoch 80 / 100\n",
      "t = 100, loss = 0.94676054\n",
      "t = 200, loss = 0.96045387\n",
      "t = 300, loss = 1.05673158\n",
      "Starting epoch 81 / 100\n",
      "t = 100, loss = 0.91606289\n",
      "t = 200, loss = 1.03754199\n",
      "t = 300, loss = 0.85887033\n",
      "Starting epoch 82 / 100\n",
      "t = 100, loss = 0.96663922\n",
      "t = 200, loss = 0.89596587\n",
      "t = 300, loss = 0.95280510\n",
      "Starting epoch 83 / 100\n",
      "t = 100, loss = 0.88796335\n",
      "t = 200, loss = 0.83399427\n",
      "t = 300, loss = 0.93300295\n",
      "Starting epoch 84 / 100\n",
      "t = 100, loss = 0.88030660\n",
      "t = 200, loss = 1.01327777\n",
      "t = 300, loss = 0.96030098\n",
      "Starting epoch 85 / 100\n",
      "t = 100, loss = 0.99084955\n",
      "t = 200, loss = 0.94287717\n",
      "t = 300, loss = 0.95680016\n",
      "Starting epoch 86 / 100\n",
      "t = 100, loss = 0.87775993\n",
      "t = 200, loss = 0.98804933\n",
      "t = 300, loss = 0.80514556\n",
      "Starting epoch 87 / 100\n",
      "t = 100, loss = 0.85324484\n",
      "t = 200, loss = 0.96675545\n",
      "t = 300, loss = 1.01774049\n",
      "Starting epoch 88 / 100\n",
      "t = 100, loss = 1.04847884\n",
      "t = 200, loss = 0.90897244\n",
      "t = 300, loss = 0.84047472\n",
      "Starting epoch 89 / 100\n",
      "t = 100, loss = 0.85808581\n",
      "t = 200, loss = 0.83819538\n",
      "t = 300, loss = 0.87138474\n",
      "Starting epoch 90 / 100\n",
      "t = 100, loss = 0.76437020\n",
      "t = 200, loss = 1.06165361\n",
      "t = 300, loss = 0.98832810\n",
      "Starting epoch 91 / 100\n",
      "t = 100, loss = 0.85405850\n",
      "t = 200, loss = 0.99100637\n",
      "t = 300, loss = 0.89026892\n",
      "Starting epoch 92 / 100\n",
      "t = 100, loss = 0.91775197\n",
      "t = 200, loss = 0.87043816\n",
      "t = 300, loss = 0.79882026\n",
      "Starting epoch 93 / 100\n",
      "t = 100, loss = 0.91882646\n",
      "t = 200, loss = 0.90641785\n",
      "t = 300, loss = 0.92547733\n",
      "Starting epoch 94 / 100\n",
      "t = 100, loss = 0.92287803\n",
      "t = 200, loss = 0.84007055\n",
      "t = 300, loss = 0.88184875\n",
      "Starting epoch 95 / 100\n",
      "t = 100, loss = 0.88012773\n",
      "t = 200, loss = 0.93789262\n",
      "t = 300, loss = 1.04712927\n",
      "Starting epoch 96 / 100\n",
      "t = 100, loss = 0.85531801\n",
      "t = 200, loss = 0.81171030\n",
      "t = 300, loss = 0.93268359\n",
      "Starting epoch 97 / 100\n",
      "t = 100, loss = 0.76804245\n",
      "t = 200, loss = 0.88839597\n",
      "t = 300, loss = 0.79345381\n",
      "Starting epoch 98 / 100\n",
      "t = 100, loss = 0.77679789\n",
      "t = 200, loss = 0.97215980\n",
      "t = 300, loss = 0.87448227\n",
      "Starting epoch 99 / 100\n",
      "t = 100, loss = 0.85038126\n",
      "t = 200, loss = 0.79589599\n",
      "t = 300, loss = 0.92127353\n",
      "Starting epoch 100 / 100\n",
      "t = 100, loss = 0.84445792\n",
      "t = 200, loss = 0.78305888\n",
      "t = 300, loss = 0.84380037\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=param['learning_rate'], weight_decay=param['weight_decay'], momentum=param['momentum'])\n",
    "\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=param['learning_rate'], weight_decay=param['weight_decay'], amsgrad=param['amsgrad'])\n",
    "\n",
    "train(net, criterion, optimizer, param, loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 70.36% (7036/10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7036"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, loader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch1.7.1+cu110",
   "language": "python",
   "name": "st-gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
