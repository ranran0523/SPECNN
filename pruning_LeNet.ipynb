{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from pruning.layers import MaskedLinear, MaskedConv2d \n",
    "from pruning.methods import filter_prune\n",
    "from pruning.utils import to_var, prune_rate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class polynom_act(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=None, beta=None, c=None):\n",
    "        super(polynom_act, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        self.beta = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        self.c = nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (self.alpha * (x ** 2) + self.beta * x + self.c)\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv1 = MaskedConv2d(1, 64, kernel_size=5, padding=2, stride=1)\n",
    "        nn.init.xavier_uniform(self.conv1.weight)\n",
    "        \n",
    "        self.relu1 = polynom_act()\n",
    "        self.avgpool1=nn.AvgPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "\n",
    "        self.conv2 = MaskedConv2d(64, 32, kernel_size=5, stride=1,groups=4)\n",
    "        nn.init.xavier_uniform(self.conv2.weight)\n",
    "        \n",
    "        self.relu2= polynom_act()\n",
    "        self.avgpool2=nn.AvgPool2d(kernel_size=10,stride=1)\n",
    "\n",
    "        self.linear1 = nn.Linear(32,32)\n",
    "        self.relu4= polynom_act()\n",
    "        self.linear2 = nn.Linear(32,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.avgpool1(self.relu1(self.conv1(x)))\n",
    "        \n",
    "        out = self.avgpool2(self.relu2(self.conv2(out)))\n",
    "\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(out.shape[0],-1)\n",
    "        \n",
    "        out = self.relu4(self.linear1(out))\n",
    "        \n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "    def set_masks(self, masks):\n",
    "        # Should be a less manual way to set masks\n",
    "        # Leave it for the future\n",
    "        self.conv1.set_mask(torch.from_numpy(masks[0]))\n",
    "        self.conv2.set_mask(torch.from_numpy(masks[1]))\n",
    "        #self.conv3.set_mask(torch.from_numpy(masks[2]))\n",
    "        self.linear1.set_mask(torch.from_numpy(masks[2]))\n",
    "        self.linear2.set_mask(torch.from_numpy(masks[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'pruning_perc': 50.,\n",
    "    'batch_size': 128, \n",
    "    'test_batch_size': 100,\n",
    "    'num_epochs': 80,\n",
    "    'learning_rate': 3e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_dataset = datasets.MNIST(root='../data/',train=True, download=True, \n",
    "    transform=transforms.ToTensor())\n",
    "loader_train = torch.utils.data.DataLoader(train_dataset, \n",
    "    batch_size=param['batch_size'], shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../data/', train=False, download=True, \n",
    "    transform=transforms.ToTensor())\n",
    "loader_test = torch.utils.data.DataLoader(test_dataset, \n",
    "    batch_size=param['test_batch_size'], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rar418/.conda/envs/st-gcn/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/rar418/.conda/envs/st-gcn/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "net = LeNet5()\n",
    "\n",
    "# Load the pretrained model\n",
    "#net.load_state_dict(torch.load('models/convnet_pretrained.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): MaskedConv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu1): polynom_act()\n",
       "  (avgpool1): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "  (conv2): MaskedConv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), groups=4)\n",
       "  (relu2): polynom_act()\n",
       "  (avgpool2): AvgPool2d(kernel_size=10, stride=1, padding=0)\n",
       "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (relu4): polynom_act()\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device) # level 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, param, loader_train, loader_val=None):\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(param['num_epochs']):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, param['num_epochs']))\n",
    "\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var, y_var = to_var(x), to_var(y.long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            loss = loss_fn(scores, y_var)\n",
    "\n",
    "            if (t + 1) % 100 == 0:\n",
    "                #print(loss.item())\n",
    "                print('t = %d, loss = %.8f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    torch.save(model.state_dict(), 'models/lenet_pretrained.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    num_correct, num_samples = 0, len(loader.dataset)\n",
    "    for x, y in loader:\n",
    "        x_var = to_var(x, volatile=True)\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "\n",
    "    acc = float(num_correct) / num_samples\n",
    "\n",
    "    print('Test accuracy: {:.2f}% ({}/{})'.format(\n",
    "        100.*acc,\n",
    "        num_correct,\n",
    "        num_samples,\n",
    "        ))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 80\n",
      "t = 100, loss = 2.29180002\n",
      "t = 200, loss = 2.03327465\n",
      "t = 300, loss = 1.50349295\n",
      "t = 400, loss = 1.17553723\n",
      "Starting epoch 2 / 80\n",
      "t = 100, loss = 0.99831265\n",
      "t = 200, loss = 1.13252389\n",
      "t = 300, loss = 0.64255744\n",
      "t = 400, loss = 0.54402000\n",
      "Starting epoch 3 / 80\n",
      "t = 100, loss = 0.46036699\n",
      "t = 200, loss = 0.55836380\n",
      "t = 300, loss = 0.44845489\n",
      "t = 400, loss = 0.45396307\n",
      "Starting epoch 4 / 80\n",
      "t = 100, loss = 0.50006825\n",
      "t = 200, loss = 0.41457841\n",
      "t = 300, loss = 0.41137362\n",
      "t = 400, loss = 0.54552788\n",
      "Starting epoch 5 / 80\n",
      "t = 100, loss = 0.47838643\n",
      "t = 200, loss = 0.44950673\n",
      "t = 300, loss = 0.28056955\n",
      "t = 400, loss = 0.35922059\n",
      "Starting epoch 6 / 80\n",
      "t = 100, loss = 0.15570737\n",
      "t = 200, loss = 0.38969526\n",
      "t = 300, loss = 0.32153919\n",
      "t = 400, loss = 0.54759794\n",
      "Starting epoch 7 / 80\n",
      "t = 100, loss = 0.33928177\n",
      "t = 200, loss = 0.24040742\n",
      "t = 300, loss = 0.19568352\n",
      "t = 400, loss = 0.25796962\n",
      "Starting epoch 8 / 80\n",
      "t = 100, loss = 0.44279936\n",
      "t = 200, loss = 0.19115177\n",
      "t = 300, loss = 0.31218836\n",
      "t = 400, loss = 0.44395038\n",
      "Starting epoch 9 / 80\n",
      "t = 100, loss = 0.32053834\n",
      "t = 200, loss = 0.17249776\n",
      "t = 300, loss = 0.36606187\n",
      "t = 400, loss = 0.22351831\n",
      "Starting epoch 10 / 80\n",
      "t = 100, loss = 0.28270096\n",
      "t = 200, loss = 0.34915262\n",
      "t = 300, loss = 0.24373606\n",
      "t = 400, loss = 0.33154023\n",
      "Starting epoch 11 / 80\n",
      "t = 100, loss = 0.21564031\n",
      "t = 200, loss = 0.25563210\n",
      "t = 300, loss = 0.27655131\n",
      "t = 400, loss = 0.32664448\n",
      "Starting epoch 12 / 80\n",
      "t = 100, loss = 0.23292300\n",
      "t = 200, loss = 0.14356095\n",
      "t = 300, loss = 0.10640778\n",
      "t = 400, loss = 0.36985180\n",
      "Starting epoch 13 / 80\n",
      "t = 100, loss = 0.25422060\n",
      "t = 200, loss = 0.24430372\n",
      "t = 300, loss = 0.27576646\n",
      "t = 400, loss = 0.09302159\n",
      "Starting epoch 14 / 80\n",
      "t = 100, loss = 0.10068849\n",
      "t = 200, loss = 0.13530935\n",
      "t = 300, loss = 0.25643474\n",
      "t = 400, loss = 0.37728819\n",
      "Starting epoch 15 / 80\n",
      "t = 100, loss = 0.18476637\n",
      "t = 200, loss = 0.19470914\n",
      "t = 300, loss = 0.13643108\n",
      "t = 400, loss = 0.15545349\n",
      "Starting epoch 16 / 80\n",
      "t = 100, loss = 0.14560585\n",
      "t = 200, loss = 0.13726330\n",
      "t = 300, loss = 0.12923165\n",
      "t = 400, loss = 0.21679009\n",
      "Starting epoch 17 / 80\n",
      "t = 100, loss = 0.11851031\n",
      "t = 200, loss = 0.08943865\n",
      "t = 300, loss = 0.18741684\n",
      "t = 400, loss = 0.09298973\n",
      "Starting epoch 18 / 80\n",
      "t = 100, loss = 0.19334418\n",
      "t = 200, loss = 0.11474165\n",
      "t = 300, loss = 0.17936063\n",
      "t = 400, loss = 0.12571509\n",
      "Starting epoch 19 / 80\n",
      "t = 100, loss = 0.13033608\n",
      "t = 200, loss = 0.15413007\n",
      "t = 300, loss = 0.16010623\n",
      "t = 400, loss = 0.15613313\n",
      "Starting epoch 20 / 80\n",
      "t = 100, loss = 0.13109422\n",
      "t = 200, loss = 0.13791922\n",
      "t = 300, loss = 0.11834536\n",
      "t = 400, loss = 0.15708746\n",
      "Starting epoch 21 / 80\n",
      "t = 100, loss = 0.11875750\n",
      "t = 200, loss = 0.17949188\n",
      "t = 300, loss = 0.16563788\n",
      "t = 400, loss = 0.16795555\n",
      "Starting epoch 22 / 80\n",
      "t = 100, loss = 0.08476646\n",
      "t = 200, loss = 0.12009665\n",
      "t = 300, loss = 0.10112303\n",
      "t = 400, loss = 0.11462747\n",
      "Starting epoch 23 / 80\n",
      "t = 100, loss = 0.05847042\n",
      "t = 200, loss = 0.18682154\n",
      "t = 300, loss = 0.05159503\n",
      "t = 400, loss = 0.05522370\n",
      "Starting epoch 24 / 80\n",
      "t = 100, loss = 0.10453433\n",
      "t = 200, loss = 0.07835028\n",
      "t = 300, loss = 0.05125815\n",
      "t = 400, loss = 0.17089522\n",
      "Starting epoch 25 / 80\n",
      "t = 100, loss = 0.03133096\n",
      "t = 200, loss = 0.09992559\n",
      "t = 300, loss = 0.04748790\n",
      "t = 400, loss = 0.14621158\n",
      "Starting epoch 26 / 80\n",
      "t = 100, loss = 0.17649287\n",
      "t = 200, loss = 0.08384347\n",
      "t = 300, loss = 0.08623939\n",
      "t = 400, loss = 0.15046856\n",
      "Starting epoch 27 / 80\n",
      "t = 100, loss = 0.05894107\n",
      "t = 200, loss = 0.07870822\n",
      "t = 300, loss = 0.07210935\n",
      "t = 400, loss = 0.07208565\n",
      "Starting epoch 28 / 80\n",
      "t = 100, loss = 0.09391961\n",
      "t = 200, loss = 0.07565462\n",
      "t = 300, loss = 0.15826064\n",
      "t = 400, loss = 0.06369881\n",
      "Starting epoch 29 / 80\n",
      "t = 100, loss = 0.11683129\n",
      "t = 200, loss = 0.04630148\n",
      "t = 300, loss = 0.03949575\n",
      "t = 400, loss = 0.08740544\n",
      "Starting epoch 30 / 80\n",
      "t = 100, loss = 0.04599738\n",
      "t = 200, loss = 0.15111485\n",
      "t = 300, loss = 0.20814081\n",
      "t = 400, loss = 0.17577289\n",
      "Starting epoch 31 / 80\n",
      "t = 100, loss = 0.08058531\n",
      "t = 200, loss = 0.04110657\n",
      "t = 300, loss = 0.13015652\n",
      "t = 400, loss = 0.05816808\n",
      "Starting epoch 32 / 80\n",
      "t = 100, loss = 0.05529793\n",
      "t = 200, loss = 0.09469917\n",
      "t = 300, loss = 0.06662453\n",
      "t = 400, loss = 0.02775490\n",
      "Starting epoch 33 / 80\n",
      "t = 100, loss = 0.09772416\n",
      "t = 200, loss = 0.07954223\n",
      "t = 300, loss = 0.15631926\n",
      "t = 400, loss = 0.07577977\n",
      "Starting epoch 34 / 80\n",
      "t = 100, loss = 0.10105482\n",
      "t = 200, loss = 0.08568533\n",
      "t = 300, loss = 0.04296710\n",
      "t = 400, loss = 0.05343626\n",
      "Starting epoch 35 / 80\n",
      "t = 100, loss = 0.07998579\n",
      "t = 200, loss = 0.03102444\n",
      "t = 300, loss = 0.13353793\n",
      "t = 400, loss = 0.09571687\n",
      "Starting epoch 36 / 80\n",
      "t = 100, loss = 0.03000120\n",
      "t = 200, loss = 0.07118788\n",
      "t = 300, loss = 0.06609962\n",
      "t = 400, loss = 0.14599612\n",
      "Starting epoch 37 / 80\n",
      "t = 100, loss = 0.06814647\n",
      "t = 200, loss = 0.11354412\n",
      "t = 300, loss = 0.03957767\n",
      "t = 400, loss = 0.02350133\n",
      "Starting epoch 38 / 80\n",
      "t = 100, loss = 0.03058697\n",
      "t = 200, loss = 0.12333116\n",
      "t = 300, loss = 0.09277108\n",
      "t = 400, loss = 0.04478867\n",
      "Starting epoch 39 / 80\n",
      "t = 100, loss = 0.05666138\n",
      "t = 200, loss = 0.18094744\n",
      "t = 300, loss = 0.08063496\n",
      "t = 400, loss = 0.11601259\n",
      "Starting epoch 40 / 80\n",
      "t = 100, loss = 0.04532289\n",
      "t = 200, loss = 0.01706128\n",
      "t = 300, loss = 0.06023499\n",
      "t = 400, loss = 0.02533994\n",
      "Starting epoch 41 / 80\n",
      "t = 100, loss = 0.05892043\n",
      "t = 200, loss = 0.04452188\n",
      "t = 300, loss = 0.07920014\n",
      "t = 400, loss = 0.01820652\n",
      "Starting epoch 42 / 80\n",
      "t = 100, loss = 0.05531455\n",
      "t = 200, loss = 0.11073083\n",
      "t = 300, loss = 0.04114113\n",
      "t = 400, loss = 0.07452685\n",
      "Starting epoch 43 / 80\n",
      "t = 100, loss = 0.04922643\n",
      "t = 200, loss = 0.02491268\n",
      "t = 300, loss = 0.04145454\n",
      "t = 400, loss = 0.10785694\n",
      "Starting epoch 44 / 80\n",
      "t = 100, loss = 0.02665250\n",
      "t = 200, loss = 0.02711587\n",
      "t = 300, loss = 0.01529428\n",
      "t = 400, loss = 0.01561700\n",
      "Starting epoch 45 / 80\n",
      "t = 100, loss = 0.09298351\n",
      "t = 200, loss = 0.00737693\n",
      "t = 300, loss = 0.03331071\n",
      "t = 400, loss = 0.03437839\n",
      "Starting epoch 46 / 80\n",
      "t = 100, loss = 0.03707018\n",
      "t = 200, loss = 0.03154292\n",
      "t = 300, loss = 0.01871648\n",
      "t = 400, loss = 0.05147236\n",
      "Starting epoch 47 / 80\n",
      "t = 100, loss = 0.04848009\n",
      "t = 200, loss = 0.05081155\n",
      "t = 300, loss = 0.03771189\n",
      "t = 400, loss = 0.02586296\n",
      "Starting epoch 48 / 80\n",
      "t = 100, loss = 0.04488270\n",
      "t = 200, loss = 0.05637417\n",
      "t = 300, loss = 0.02006013\n",
      "t = 400, loss = 0.04823340\n",
      "Starting epoch 49 / 80\n",
      "t = 100, loss = 0.05054179\n",
      "t = 200, loss = 0.01541563\n",
      "t = 300, loss = 0.06107732\n",
      "t = 400, loss = 0.00618687\n",
      "Starting epoch 50 / 80\n",
      "t = 100, loss = 0.06047228\n",
      "t = 200, loss = 0.03097674\n",
      "t = 300, loss = 0.10592951\n",
      "t = 400, loss = 0.01833459\n",
      "Starting epoch 51 / 80\n",
      "t = 100, loss = 0.00460560\n",
      "t = 200, loss = 0.00675304\n",
      "t = 300, loss = 0.08947119\n",
      "t = 400, loss = 0.02966447\n",
      "Starting epoch 52 / 80\n",
      "t = 100, loss = 0.03439216\n",
      "t = 200, loss = 0.10436513\n",
      "t = 300, loss = 0.02915579\n",
      "t = 400, loss = 0.03967506\n",
      "Starting epoch 53 / 80\n",
      "t = 100, loss = 0.04550382\n",
      "t = 200, loss = 0.04482629\n",
      "t = 300, loss = 0.09971495\n",
      "t = 400, loss = 0.18786055\n",
      "Starting epoch 54 / 80\n",
      "t = 100, loss = 0.01559310\n",
      "t = 200, loss = 0.01574667\n",
      "t = 300, loss = 0.06846886\n",
      "t = 400, loss = 0.01957111\n",
      "Starting epoch 55 / 80\n",
      "t = 100, loss = 0.09437318\n",
      "t = 200, loss = 0.04514995\n",
      "t = 300, loss = 0.01329620\n",
      "t = 400, loss = 0.09487732\n",
      "Starting epoch 56 / 80\n",
      "t = 100, loss = 0.02809949\n",
      "t = 200, loss = 0.05009715\n",
      "t = 300, loss = 0.02305828\n",
      "t = 400, loss = 0.04906946\n",
      "Starting epoch 57 / 80\n",
      "t = 100, loss = 0.03796088\n",
      "t = 200, loss = 0.01501032\n",
      "t = 300, loss = 0.01121655\n",
      "t = 400, loss = 0.03467514\n",
      "Starting epoch 58 / 80\n",
      "t = 100, loss = 0.03510301\n",
      "t = 200, loss = 0.01924755\n",
      "t = 300, loss = 0.05648199\n",
      "t = 400, loss = 0.15223084\n",
      "Starting epoch 59 / 80\n",
      "t = 100, loss = 0.03535971\n",
      "t = 200, loss = 0.04172401\n",
      "t = 300, loss = 0.02654799\n",
      "t = 400, loss = 0.07692240\n",
      "Starting epoch 60 / 80\n",
      "t = 100, loss = 0.11168718\n",
      "t = 200, loss = 0.02776351\n",
      "t = 300, loss = 0.04101736\n",
      "t = 400, loss = 0.00641888\n",
      "Starting epoch 61 / 80\n",
      "t = 100, loss = 0.02563793\n",
      "t = 200, loss = 0.02869209\n",
      "t = 300, loss = 0.01585435\n",
      "t = 400, loss = 0.07134748\n",
      "Starting epoch 62 / 80\n",
      "t = 100, loss = 0.09153948\n",
      "t = 200, loss = 0.01269869\n",
      "t = 300, loss = 0.04074045\n",
      "t = 400, loss = 0.04509134\n",
      "Starting epoch 63 / 80\n",
      "t = 100, loss = 0.01306530\n",
      "t = 200, loss = 0.02362604\n",
      "t = 300, loss = 0.02093842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 400, loss = 0.01821338\n",
      "Starting epoch 64 / 80\n",
      "t = 100, loss = 0.02266996\n",
      "t = 200, loss = 0.03756992\n",
      "t = 300, loss = 0.03218032\n",
      "t = 400, loss = 0.01958508\n",
      "Starting epoch 65 / 80\n",
      "t = 100, loss = 0.04024110\n",
      "t = 200, loss = 0.06464313\n",
      "t = 300, loss = 0.01070078\n",
      "t = 400, loss = 0.02153328\n",
      "Starting epoch 66 / 80\n",
      "t = 100, loss = 0.01210746\n",
      "t = 200, loss = 0.01451194\n",
      "t = 300, loss = 0.08940686\n",
      "t = 400, loss = 0.03579009\n",
      "Starting epoch 67 / 80\n",
      "t = 100, loss = 0.02704545\n",
      "t = 200, loss = 0.03648291\n",
      "t = 300, loss = 0.00855329\n",
      "t = 400, loss = 0.02647634\n",
      "Starting epoch 68 / 80\n",
      "t = 100, loss = 0.02475363\n",
      "t = 200, loss = 0.02709866\n",
      "t = 300, loss = 0.01295702\n",
      "t = 400, loss = 0.01902932\n",
      "Starting epoch 69 / 80\n",
      "t = 100, loss = 0.05978847\n",
      "t = 200, loss = 0.02551782\n",
      "t = 300, loss = 0.09170306\n",
      "t = 400, loss = 0.00980793\n",
      "Starting epoch 70 / 80\n",
      "t = 100, loss = 0.02474120\n",
      "t = 200, loss = 0.03156541\n",
      "t = 300, loss = 0.03274680\n",
      "t = 400, loss = 0.07724077\n",
      "Starting epoch 71 / 80\n",
      "t = 100, loss = 0.05480339\n",
      "t = 200, loss = 0.02383107\n",
      "t = 300, loss = 0.00605409\n",
      "t = 400, loss = 0.03701182\n",
      "Starting epoch 72 / 80\n",
      "t = 100, loss = 0.03597897\n",
      "t = 200, loss = 0.02228397\n",
      "t = 300, loss = 0.04171963\n",
      "t = 400, loss = 0.03790827\n",
      "Starting epoch 73 / 80\n",
      "t = 100, loss = 0.06916742\n",
      "t = 200, loss = 0.02080697\n",
      "t = 300, loss = 0.02686195\n",
      "t = 400, loss = 0.05020513\n",
      "Starting epoch 74 / 80\n",
      "t = 100, loss = 0.02027799\n",
      "t = 200, loss = 0.02774313\n",
      "t = 300, loss = 0.01025532\n",
      "t = 400, loss = 0.02066741\n",
      "Starting epoch 75 / 80\n",
      "t = 100, loss = 0.01686205\n",
      "t = 200, loss = 0.00774742\n",
      "t = 300, loss = 0.01406569\n",
      "t = 400, loss = 0.00372000\n",
      "Starting epoch 76 / 80\n",
      "t = 100, loss = 0.00354706\n",
      "t = 200, loss = 0.01189325\n",
      "t = 300, loss = 0.01039296\n",
      "t = 400, loss = 0.02832864\n",
      "Starting epoch 77 / 80\n",
      "t = 100, loss = 0.02151489\n",
      "t = 200, loss = 0.00452950\n",
      "t = 300, loss = 0.00885962\n",
      "t = 400, loss = 0.00866054\n",
      "Starting epoch 78 / 80\n",
      "t = 100, loss = 0.02876901\n",
      "t = 200, loss = 0.00688439\n",
      "t = 300, loss = 0.01736846\n",
      "t = 400, loss = 0.05404118\n",
      "Starting epoch 79 / 80\n",
      "t = 100, loss = 0.01485812\n",
      "t = 200, loss = 0.01057320\n",
      "t = 300, loss = 0.06553370\n",
      "t = 400, loss = 0.04702269\n",
      "Starting epoch 80 / 80\n",
      "t = 100, loss = 0.10522140\n",
      "t = 200, loss = 0.00365737\n",
      "t = 300, loss = 0.02139924\n",
      "t = 400, loss = 0.01577161\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=param['learning_rate'], weight_decay=param['weight_decay'])\n",
    "\n",
    "train(net, criterion, optimizer, param, loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./models/lenet_pretrained.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rar418/pytorch-weights_pruning/pruning/utils.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(x, requires_grad=requires_grad, volatile=volatile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.69% (9869/10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9869"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, loader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch1.7.1+cu110",
   "language": "python",
   "name": "st-gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
